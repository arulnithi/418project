{
  "name": "ParaPy",
  "tagline": "It's like CUDA, but for Python",
  "body": "# Proposal\r\n\r\n### Team Members\r\nArulnithi Sundaramoorthy (arulnits)\r\n\r\nRam Verma (ramv)\r\n\r\n\r\n### Summary\r\nWe are going to implement a Python module which takes Python code and translates it to C++ code targeting a CUDA compiler for the execution of the code.\r\n\r\n\r\n### Background\r\nPython is a widely used, general purpose, interpreted programming language whose code allows users to express concepts in fewer lines of code as compared to C++ or Java. However, Python suffers from being slow due to its Global Interpreter Lock (GIL) which does not allow multi-threading. \r\n\r\nTo combat this, there are many libraries which exist to allow multi-threading in Python such as processing which is a fork based process creation tool and Cython which allows calls to C libraries for parallelism. Moreover, PyCuda allows the user to type in C as part of a larger Python program to harness the power of GPUs. However, most of these tools are either restricted by the GIL or require some form of C/C++ code on top of Python code. \r\n\r\n____\r\nThus, we want to have a module which allows you to write standard Python syntax code and use just the methods of our module to harness the full potential of GPUs. \r\n___\r\n\r\n### The Challenge\r\nThere are many challenges associated with the project. We will have to correctly translate Python code to C++ CUDA code. This is a challenging task given the nature of both languages. Python is dynamically typed, meaning that there is no static type information available. We will require the user to confirm to certain restrictions ( not calling nested functions, using data of a singular primitive types, declaring type information before hand). \r\n\r\nAnother challenge is CUDAâ€™s distinction between device memory and host memory, and also the availability of shared memory to achieve even greater speed up. Python only has one type of memory, and hence we need to identify when and how such memory needs to be allocated. We plan to take care of device and host memory transfers, and disregard potential speedups achieved from shared memory optimizations. \r\n\r\n### Resources\r\nWe are planning to use several built in modules that allow for source code manipulation.The _Inspect module_ provides several useful functions to help get information about live objects such as classes and functions and retrieve their source code. The _AST module_ then allows us to generate an abstract syntax tree from this Python source code. We would then proceed to generate compliable C++ CUDA code using the above information.\r\n\r\n### Goals and Deliverables\r\n####*PLAN TO ACHIEVE*\r\nWe plan to have a completed Python module compiler which generates and compiles CUDA code for written Python code. The compiler should support arithmetic and boolean operations as well as libraries common to Python and C++.  \r\n####*HOPE TO ACHIEVE*\r\nIf we are able to complete the module compiler for CUDA, we plan to introduce finer level of control over the kernel calls in the compiler. We would also like to look into support for CPU parallelism by generating C++ code which uses OpenMP.\r\n\r\n\r\n### Platform Choice\r\nWe chose Python due to its simplicity and availability of multiple libraries for source code parsing. By having a module such as ParaPy, we hope to combine the simplicity of Python with the speed of C++.\r\n\r\nWe will be using the GHC 5000 machines with NVIDIA GPUs for design verification and testing since the NVIDIA compiler (nvcc) has already been set up on the machines.\r\n\r\n### Schedule\r\n    April 4th - 10th\r\n    -Read and understand Python libraries which support processing of Python syntax grammar\r\n    -Write the parser functions using the Python libraries as the first step for our module\r\n\r\n    April 11th - 17th\r\n    -Generate CUDA kernel code without errors given Python function which meets basic requirements \r\n    -Basic requirements include only arithmetic operations and no function calls within a function\r\n    -Work on checkpoint report\r\n\r\n    April 18th - 24th\r\n    -Compile module on the Mandelbrot function and compare speedup to standard Python implementation\r\n    -Produce graphs for comparison \r\n\r\n    April 25th - 30th\r\n    -Add more functionality to support generic library calls for the compiler\r\n    -Start working on generating OpenMP code if times permits\r\n\r\n    May 1st - 7th\r\n    -Finalize the module compiler and fix any bugs\r\n    -Work on report and website",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}